<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Assistant</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
        }
        .container {
            display: flex;
            flex-direction: column;
            gap: 20px;
        }
        .chat-area {
            height: 400px;
            border: 1px solid #ccc;
            padding: 15px;
            overflow-y: auto;
            border-radius: 8px;
        }
        .message {
            margin-bottom: 10px;
            padding: 10px;
            border-radius: 8px;
            max-width: 80%;
        }
        .user-message {
            background-color: #e3f2fd;
            align-self: flex-end;
            margin-left: auto;
        }
        .assistant-message {
            background-color: #f5f5f5;
            align-self: flex-start;
        }
        .input-area {
            display: flex;
            gap: 10px;
        }
        #user-input {
            flex-grow: 1;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 4px;
        }
        button {
            padding: 10px 15px;
            background-color: #4285f4;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
        }
        button:hover {
            background-color: #2b6cb0;
        }
        .api-key-area {
            margin-bottom: 20px;
        }
        #api-key {
            width: 100%;
            padding: 10px;
            margin-bottom: 10px;
            border: 1px solid #ccc;
            border-radius: 4px;
        }
        .controls {
            display: flex;
            gap: 10px;
            margin-top: 10px;
        }
        .listening {
            color: red;
            font-weight: bold;
            animation: pulse 1.5s infinite;
        }
        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.5; }
            100% { opacity: 1; }
        }
    </style>
</head>
<body>
    <h1>Voice Assistant</h1>
    <div class="container">
        <div class="api-key-area">
            <label for="api-key">Enter your Gemini API Key:</label>
            <input type="password" id="api-key" placeholder="Your API key" />
            <p><small>Your API key is stored locally and never sent to any server except Google's API.</small></p>
        </div>
        
        <div class="chat-area" id="chat-area"></div>
        
        <div class="input-area">
            <input type="text" id="user-input" placeholder="Type your message..." />
            <button id="send-btn">Send</button>
        </div>
        
        <div class="controls">
            <button id="speak-btn">Start Voice Input</button>
            <button id="toggle-speech-btn">Enable Voice Response</button>
            <span id="listening-indicator"></span>
        </div>
    </div>

    <script>
        // Set up DOM elements
        const chatArea = document.getElementById('chat-area');
        const userInput = document.getElementById('user-input');
        const sendBtn = document.getElementById('send-btn');
        const speakBtn = document.getElementById('speak-btn');
        const toggleSpeechBtn = document.getElementById('toggle-speech-btn');
        const listeningIndicator = document.getElementById('listening-indicator');
        const apiKeyInput = document.getElementById('api-key');
        
        // Chat history
        let chatHistory = [];
        
        // Speech synthesis setup
        const synth = window.speechSynthesis;
        let isSpeechEnabled = false;
        
        // Speech recognition setup
        let recognition = null;
        if ('SpeechRecognition' in window || 'webkitSpeechRecognition' in window) {
            recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
            recognition.continuous = false;
            recognition.interimResults = false;
            
            recognition.onresult = (event) => {
                const transcript = event.results[0][0].transcript;
                userInput.value = transcript;
                sendMessage();
            };
            
            recognition.onstart = () => {
                listeningIndicator.textContent = "Listening...";
                listeningIndicator.classList.add('listening');
            };
            
            recognition.onend = () => {
                listeningIndicator.textContent = "";
                listeningIndicator.classList.remove('listening');
            };
        }
        
        // Toggle speech output
        toggleSpeechBtn.addEventListener('click', () => {
            isSpeechEnabled = !isSpeechEnabled;
            toggleSpeechBtn.textContent = isSpeechEnabled ? "Disable Voice Response" : "Enable Voice Response";
        });
        
        // Start voice input
        speakBtn.addEventListener('click', () => {
            if (recognition) {
                recognition.start();
            } else {
                alert("Speech recognition is not supported in your browser.");
            }
        });
        
        // Send message when button is clicked
        sendBtn.addEventListener('click', sendMessage);
        
        // Send message when Enter key is pressed
        userInput.addEventListener('keypress', function(e) {
            if (e.key === 'Enter') {
                sendMessage();
            }
        });
        
        async function sendMessage() {
            const message = userInput.value.trim();
            if (message === '') return;
            
            const apiKey = apiKeyInput.value.trim();
            if (apiKey === '') {
                alert("Please enter your Gemini API key");
                return;
            }
            
            // Add user message to chat
            addMessageToChat('user', message);
            userInput.value = '';
            
            try {
                // Create a loading message
                const loadingElement = document.createElement('div');
                loadingElement.className = 'message assistant-message';
                loadingElement.textContent = 'Thinking...';
                chatArea.appendChild(loadingElement);
                chatArea.scrollTop = chatArea.scrollHeight;
                
                // Send message to Gemini API
                const response = await callGeminiAPI(apiKey, message);
                
                // Remove loading message
                chatArea.removeChild(loadingElement);
                
                // Add assistant's response to chat
                addMessageToChat('assistant', response);
                
                // Speak response if enabled
                if (isSpeechEnabled) {
                    speakText(response);
                }
            } catch (error) {
                console.error('Error:', error);
                chatArea.removeChild(chatArea.lastChild); // Remove loading message
                addMessageToChat('assistant', `Error: ${error.message}`);
            }
        }
        
        function addMessageToChat(role, content) {
            const messageElement = document.createElement('div');
            messageElement.className = `message ${role}-message`;
            messageElement.textContent = content;
            chatArea.appendChild(messageElement);
            chatArea.scrollTop = chatArea.scrollHeight;
            
            // Update chat history
            chatHistory.push({ role, content });
        }
        
        async function callGeminiAPI(apiKey, message) {
            const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-03-25:generateContent?key=${apiKey}`;
            
            const requestBody = {
                contents: [
                    {
                        role: "user",
                        parts: [{ text: message }]
                    }
                ],
                generation_config: {
                    temperature: 1,
                    topP: 0.95,
                    topK: 64,
                    maxOutputTokens: 8192,
                }
            };
            
            // Add chat history if available
            if (chatHistory.length > 0) {
                requestBody.contents = chatHistory.map(msg => ({
                    role: msg.role === 'user' ? 'user' : 'model',
                    parts: [{ text: msg.content }]
                }));
                requestBody.contents.push({
                    role: "user",
                    parts: [{ text: message }]
                });
            }
            
            const response = await fetch(apiUrl, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify(requestBody)
            });
            
            if (!response.ok) {
                const errorText = await response.text();
                throw new Error(`API error (${response.status}): ${errorText}`);
            }
            
            const data = await response.json();
            
            if (data.candidates && data.candidates.length > 0 && 
                data.candidates[0].content && data.candidates[0].content.parts) {
                return data.candidates[0].content.parts[0].text;
            } else {
                throw new Error('Invalid response format');
            }
        }
        
        function speakText(text) {
            if (synth.speaking) {
                synth.cancel();
            }
            
            // Split text into manageable chunks (Web Speech API has limitations)
            const maxLength = 200;
            const textChunks = [];
            
            for (let i = 0; i < text.length; i += maxLength) {
                textChunks.push(text.substring(i, i + maxLength));
            }
            
            let chunkIndex = 0;
            
            function speakNextChunk() {
                if (chunkIndex < textChunks.length) {
                    const utterance = new SpeechSynthesisUtterance(textChunks[chunkIndex]);
                    
                    utterance.onend = () => {
                        chunkIndex++;
                        speakNextChunk();
                    };
                    
                    synth.speak(utterance);
                }
            }
            
            speakNextChunk();
        }
    </script>
</body>
</html>
